{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d794eb3e",
   "metadata": {},
   "source": [
    "## Debate Dojo\n",
    "\n",
    "You are debating an AI Opponent. However, there is a second AI (The Referee) watching.\n",
    "\n",
    "The Twist: If you (the Human) make a weak argument, use a logical fallacy, or get too emotional, the Referee blows the whistle (pauses the graph).\n",
    "\n",
    "The Human-In-the-Loop Element: The graph stops. The Referee tells you why your argument was weak. Youâ€”the humanâ€”must then rewrite your argument to meet the quality bar. Only then does the graph resume and let the Opponent reply.\n",
    "\n",
    "The Value: You are forced to improve your communication skills in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6670ff86",
   "metadata": {},
   "source": [
    "#### The Blueprint\n",
    "\n",
    "1. The State (The Shared Memory)\n",
    "\n",
    "- topic: The subject (e.g., \"Universal Basic Income\").\n",
    "\n",
    "- history: The conversation transcript.\n",
    "\n",
    "- last_human_argument: What you just said.\n",
    "\n",
    "- argument_score: 1-10 rating of your logic.\n",
    "\n",
    "- critique: The Referee's feedback.\n",
    "\n",
    "\n",
    "\n",
    "2. The Nodes (The Workers)\n",
    "\n",
    "- Node A: The Referee (Evaluator): Reads your input. Scores it. Checks for fallacies (Ad Hominem, Straw Man).\n",
    "\n",
    "- Node B: The Coach (Feedback): If score < 7, generates a helpful tip. \"You attacked the person, not the idea. Try focusing on the economic impact.\"\n",
    "\n",
    "- Node C: The Opponent (Debater): If score >= 7, generates a counter-argument to keep the debate going.\n",
    "\n",
    "\n",
    "\n",
    "3. The Flow (The Logic)\n",
    "\n",
    "- Start: User submits an argument.\n",
    "\n",
    "- Referee: Grades it.\n",
    "\n",
    "- Router (Conditional Edge):\n",
    "\n",
    "    - If Weak (Score < 7): Route to Coach. Then PAUSE (Interrupt).\n",
    "\n",
    "        - HITL Action: Human reads feedback, edits their argument, and updates the state.\n",
    "\n",
    "        - Resume: Loop back to Referee to grade the new argument.\n",
    "\n",
    "    - If Strong (Score >= 7): Route to Opponent.\n",
    "\n",
    "\n",
    "\n",
    "4. Opponent: Replies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d2b551",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabc0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Annotated\n",
    "import operator\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import BaseMessage, SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel, Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480653db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Env file\n",
    "load_dotenv()\n",
    "\n",
    "# Pass API Key to the model\n",
    "\n",
    "# Detbater (Fast, Conversational)\n",
    "debater_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=os.getenv(\"GEMINI_API_KEY\")\n",
    "    )\n",
    "\n",
    "\n",
    "# Referee (Strict, Analytical)\n",
    "referee_llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    temperature=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The State\n",
    "\n",
    "class DojoState(TypedDict):\n",
    "    topic: str\n",
    "    messages: Annotated[List[BaseMessage], operator.add] #Appends new msgs to history\n",
    "    latest_human_input: str\n",
    "    score: int\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ebe5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Schema \n",
    "\n",
    "class RefereeEvaluation(BaseModel):\n",
    "    \"\"\"Structured output for the debate referee.\"\"\"\n",
    "    score: int = Field(description=\"A score from 1-10 rating the strength and logic of the argument.\")\n",
    "    feedback: str = Field(description=\"Concise, constructive feedback explaining the score and noting any fallacies.\")\n",
    "    fallacy_detected: bool = Field(description=\"True if a fallacy (Ad Hominem, Straw Man, etc.) was detected, False otherwise.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876ea69",
   "metadata": {},
   "source": [
    "#### The Nodes (Workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Nodes (Workers)\n",
    "\n",
    "# Referee Node\n",
    "\n",
    "def referee_node(state: DojoState):\n",
    "    \"\"\"The Judge: Grades the human's latest argument using structured output.\"\"\"\n",
    "    human_arg = state[\"latest_human_input\"]\n",
    "\n",
    "    print(f\"\\n---REFEREE ANALYZING: '{human_arg}' ---\")\n",
    "\n",
    "    # Create a specialized LLM wrapper that ONLY returns our Pydantic object\n",
    "    structured_llm = referee_llm.with_structured_output(RefereeEvaluation)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a debate referee. \n",
    "    Analyze the user's argument \"{human_arg}\" for the topic: {state[\"topic\"]}.\n",
    "\n",
    "    Evaluate strictly on the following criteria:\n",
    "    1. Logical fallacies (Ad Hominem, Straw Man, Slippery Slope, etc.).\n",
    "    2. Clarity and relevance.\n",
    "\n",
    "    Be struct. High scores (8+) require perfect logic. \n",
    "    \"\"\"\n",
    "\n",
    "    # Invoke. The result is NOT a string message; it is a RefereeEvaluation object\n",
    "    result: RefereeEvaluation = structured_llm.invoke([\n",
    "        SystemMessage(content=prompt),\n",
    "        HumanMessage(content=human_arg)\n",
    "        ])\n",
    "   \n",
    "    return {\n",
    "        \"score\": result.score,\n",
    "        \"feedback\": result.feedback,\n",
    "        \"fallacy_detected\": result.fallacy_detected\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8152013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coach Node\n",
    "\n",
    "def coach_node(state: DojoState):\n",
    "    \"\"\"The Coach: Tells the user why they paused..\"\"\"\n",
    "    # We don't need an LLM here, just logic to display the feedback.\n",
    "    # In an UI, this would send message to the frontend. \n",
    "\n",
    "    print(f\"\\nâœ‹ PAUSE! WEAK ARGUMENT (Score: {state['score']}/10)\")\n",
    "    print(f\"ðŸ’¡ COACH SAYS: {state['feedback']}\")\n",
    "    print(\"ðŸ‘‰ Please refine your argument and try again.\")\n",
    "    \n",
    "    # we return nothing because we are just preparing for interruption\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191bf031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opponent Node\n",
    "\n",
    "def opponent_node(state: DojoState):\n",
    "    \"\"\"The Opponent: Generates a counter-argument if the user argument logic was sound.\"\"\"\n",
    "    print(f\"\\n Opponent Responds...\")\n",
    "\n",
    "    # Context: the History + the approved new argument\n",
    "    msgs = state[\"messages\"] + [HumanMessage(content=state[\"latest_human_input\"])]\n",
    "\n",
    "    system_prompt = f\"You are debating the topic: {state['topic']}. Be short, witty, and logical. Disagree with the user.\"\n",
    "\n",
    "    response = debater_llm.invoke([\n",
    "        SystemMessage(content=system_prompt)] + msgs)\n",
    "\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94090732",
   "metadata": {},
   "source": [
    "#### The Graph and the Loop\n",
    "\n",
    "We wire the nodes together and define the interruption.\n",
    "We want to route tothe coach, and then stop after the coach delivers the bad news, so user can fix it.\n",
    "Actually, the cleanest pattern is to interrupt before we loop back to the referee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb1926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Graph & the Loop\n",
    "workflow = StateGraph(DojoState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"referee\", referee_node)\n",
    "workflow.add_node(\"coach\", coach_node)\n",
    "workflow.add_node(\"opponent\", opponent_node)\n",
    "\n",
    "# Entry Point\n",
    "workflow.set_entry_point(\"referee\")\n",
    "\n",
    "# Router Logic: Where do we do after the Referee grades?\n",
    "def router(state: DojoState):\n",
    "    if state[\"score\"] >= 7:\n",
    "        return \"approved\"\n",
    "    else:\n",
    "        return \"rejected\"\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"referee\", \n",
    "    router,\n",
    "    {\n",
    "        \"approved\": \"opponent\",\n",
    "        \"rejected\": \"coach\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# If rejected, we go to Coach\n",
    "# After Coach, we want to STOP. The user must input new text.\n",
    "# Then we want to go back to the Referee to grade new text\n",
    "workflow.add_edge(\"coach\", \"referee\")\n",
    "\n",
    "# If approved, we go to Opponent, then we end. (waiting for next turn)\n",
    "workflow.add_edge(\"opponent\", END)\n",
    "\n",
    "# Memory is critical for Human-in-the-Loop\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# We interrupt before the \"referree\" runs, if we are coming from the \"coach\"\n",
    "# However a simpler way in LangGraph is to use the \"interrupt\" after the coaach node.\n",
    "app = workflow.compile(\n",
    "    checkpointer=checkpointer,\n",
    "    interrupt_after=[\"coach\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2937e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_dojo():\n",
    "    # 1. Configuration\n",
    "    # We use a static thread_id so the bot remembers the context of the debate\n",
    "    config = {\"configurable\": {\"thread_id\": \"live_user_1\"}}\n",
    "    \n",
    "    print(\"\\n--- ðŸ¥‹ WELCOME TO THE SOCRATES DOJO ðŸ¥‹ ---\")\n",
    "    topic = input(\"Enter a topic to debate (e.g., 'AI is dangerous'): \")\n",
    "    print(f\"ðŸ“ TOPIC SET: {topic}\")\n",
    "    print(\"Go ahead! Make your opening argument.\\n\")\n",
    "\n",
    "    # 2. The Interactive Loop\n",
    "    while True:\n",
    "        # Get User Input\n",
    "        user_input = input(\"ðŸ‘¤ YOU: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "            print(\"Exiting Dojo...\")\n",
    "            break\n",
    "\n",
    "        # 3. Check Graph Status: Are we fixing a mistake or starting a new turn?\n",
    "        snapshot = app.get_state(config)\n",
    "        \n",
    "        if snapshot.next:\n",
    "            # --- CORRECTION MODE ---\n",
    "            # If snapshot.next is not empty, the graph is PAUSED at the 'coach' interrupt.\n",
    "            # We are submitting a REWRITE, not a new argument.\n",
    "            \n",
    "            print(\"   (Submitting correction to Referee...)\")\n",
    "            \n",
    "            # A. Update the state with the fixed text\n",
    "            app.update_state(config, {\"latest_human_input\": user_input})\n",
    "            \n",
    "            # B. Resume the graph (None tells it to continue execution)\n",
    "            # The graph flows: Coach -> Referee (Re-Grade) -> Router\n",
    "            events = app.stream(None, config)\n",
    "            \n",
    "        else:\n",
    "            # --- NORMAL MODE ---\n",
    "            # The graph is IDLE (at END). We are starting a fresh turn.\n",
    "            \n",
    "            # We pass the input to start the run from the top (Referee)\n",
    "            events = app.stream(\n",
    "                {\"topic\": topic, \"latest_human_input\": user_input}, \n",
    "                config\n",
    "            )\n",
    "\n",
    "        # 4. Handle the Output\n",
    "        # We run the stream to let the graph execute\n",
    "        for event in events:\n",
    "            # Optional: You could print \"Thinking...\" here if you wanted\n",
    "            pass\n",
    "            \n",
    "        # 5. Post-Execution Check\n",
    "        # Did we finish successfully (Opponent spoke)? \n",
    "        # Or did we get paused again (Coach rejected)?\n",
    "        snapshot = app.get_state(config)\n",
    "        \n",
    "        if snapshot.next:\n",
    "            # PAUSED: The Referee rejected us again (or for the first time)\n",
    "            score = snapshot.values.get('score')\n",
    "            feedback = snapshot.values.get('feedback')\n",
    "            \n",
    "            print(f\"\\nâœ‹ COACH INTERRUPT (Score: {score}/10)\")\n",
    "            print(f\"ðŸ’¡ Feedback: {feedback}\")\n",
    "            print(\"ðŸ‘‰ Try rewriting your argument based on this feedback.\\n\")\n",
    "            # The loop restarts, and your next input will go to the 'Correction Mode' block\n",
    "            \n",
    "        else:\n",
    "            # SUCCESS: The Opponent responded\n",
    "            if 'messages' in snapshot.values and len(snapshot.values['messages']) > 0:\n",
    "                last_msg = snapshot.values['messages'][-1]\n",
    "                print(f\"\\nðŸ¤– OPPONENT: {last_msg.content}\\n\")\n",
    "            else:\n",
    "                # Edge case handling\n",
    "                print(\"Error: No response generated.\")\n",
    "\n",
    "# Run it\n",
    "if __name__ == \"__main__\":\n",
    "    chat_with_dojo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08395dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
