{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f479b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew, Process, LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e2308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API key\n",
    "# Set API key (if using OpenAI instead of local LLM)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"  # Or better: use python-dotenv to load from .env file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623db9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = LLM(\n",
    "    model=\"ollama/llama3.1\",\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "480d8183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define the Agent\n",
    "researcher_agent = Agent(\n",
    "    role = \"senior researcher\",\n",
    "    goal = \"Uncover ground-breaking insights, technologies  and trends in AI\",\n",
    "    backstory = \"You are a senior researcher with 20 years of experience in AI research. You have published 100 papers in top-tier journals and conferences. You are a leading expert in AI research and are known for your ability to uncover ground-breaking insights, technologies  and trends in AI.\",\n",
    "    verbose = True,\n",
    "    allow_delegation = False,\n",
    "    llm = local_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d6545db",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_agent = Agent(\n",
    "    role=\"Writer\",\n",
    "    goal=\"Write a tutorial about setting up local AI\",\n",
    "    backstory=\"You are a writer with 20 years of experience in writing books. You have published 100 books in top-tier journals and conferences. You are a leading expert in writing books and are known for your ability to write books about AI.\",\n",
    "    verbose = True,\n",
    "    allow_delegation = False,\n",
    "    llm = local_llm\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82e5e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Define the Task\n",
    "task1 = Task(\n",
    "    description = \"Research on AI trends\",\n",
    "    expected_output = \"A 6 bullets summary of the trends\",\n",
    "    agent = researcher_agent\n",
    ")\n",
    "\n",
    "task2 = Task(\n",
    "    description = \"Write a short blog post about running llama models in Macbook Air M3\",\n",
    "    expected_output = \"Crisp one pragraph synopsis of the blog post\",\n",
    "    agent = writer_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd7318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define the Crew\n",
    "crew = Crew(\n",
    "  agents=[researcher_agent, writer_agent],\n",
    "  tasks=[task1, task2],\n",
    "  process = Process.sequential,\n",
    "  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82ccbdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Crew Execution Started \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Crew Execution Started</span>                                                                                         <span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008080; text-decoration-color: #008080\">crew</span>                                                                                                     <span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008080; text-decoration-color: #008080\">6597fdea-4dbf-4057-8da0-0faf4c17a77d</span>                                                                       <span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>                                                                                                                 <span style=\"color: #008080; text-decoration-color: #008080\">\u2502</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[36m\u256d\u2500\u001b[0m\u001b[36m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[36m Crew Execution Started \u001b[0m\u001b[36m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[36m\u2500\u256e\u001b[0m\n",
       "\u001b[36m\u2502\u001b[0m                                                                                                                 \u001b[36m\u2502\u001b[0m\n",
       "\u001b[36m\u2502\u001b[0m  \u001b[1;36mCrew Execution Started\u001b[0m                                                                                         \u001b[36m\u2502\u001b[0m\n",
       "\u001b[36m\u2502\u001b[0m  \u001b[37mName: \u001b[0m\u001b[36mcrew\u001b[0m                                                                                                     \u001b[36m\u2502\u001b[0m\n",
       "\u001b[36m\u2502\u001b[0m  \u001b[37mID: \u001b[0m\u001b[36m6597fdea-4dbf-4057-8da0-0faf4c17a77d\u001b[0m                                                                       \u001b[36m\u2502\u001b[0m\n",
       "\u001b[36m\u2502\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[36m\u2502\u001b[0m\n",
       "\u001b[36m\u2502\u001b[0m                                                                                                                 \u001b[36m\u2502\u001b[0m\n",
       "\u001b[36m\u2502\u001b[0m                                                                                                                 \u001b[36m\u2502\u001b[0m\n",
       "\u001b[36m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83e\udd16 Agent Started \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">senior researcher</span>                                                                                       <span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Research on AI trends</span>                                                                                    <span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m\u256d\u2500\u001b[0m\u001b[35m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[35m \ud83e\udd16 Agent Started \u001b[0m\u001b[35m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[35m\u2500\u256e\u001b[0m\n",
       "\u001b[35m\u2502\u001b[0m                                                                                                                 \u001b[35m\u2502\u001b[0m\n",
       "\u001b[35m\u2502\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92msenior researcher\u001b[0m                                                                                       \u001b[35m\u2502\u001b[0m\n",
       "\u001b[35m\u2502\u001b[0m                                                                                                                 \u001b[35m\u2502\u001b[0m\n",
       "\u001b[35m\u2502\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mResearch on AI trends\u001b[0m                                                                                    \u001b[35m\u2502\u001b[0m\n",
       "\u001b[35m\u2502\u001b[0m                                                                                                                 \u001b[35m\u2502\u001b[0m\n",
       "\u001b[35m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72805027792d4940a97903af24ca79e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2705 Agent Final Answer \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">senior researcher</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">\u2022 **Increased Adoption of Explainable AI (XAI)**: With the growing concern about bias and transparency in AI </span>  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decision-making, researchers are focusing on developing methods to explain complex AI models. XAI techniques </span>  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">aim to provide a clear understanding of how AI systems arrive at their conclusions, enabling users to trust </span>   <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">and rely on them more effectively.</span>                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">\u2022 **Rise of Edge AI and IoT Convergence**: The proliferation of Internet of Things (IoT) devices has led to </span>   <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">an explosion in data generation. To address this challenge, researchers are developing edge AI technologies </span>   <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">that enable real-time processing and analysis of data at the source, reducing latency and improving </span>           <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decision-making efficiency.</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">\u2022 **Advancements in Transfer Learning and Few-Shot Learning**: As large datasets become increasingly </span>          <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">available, researchers are exploring ways to transfer knowledge between related tasks or domains. This shift </span>  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">towards transfer learning and few-shot learning aims to reduce the need for extensive retraining and improve </span>  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">model adaptability.</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">\u2022 **Emergence of Causal AI**: Recognizing that traditional machine learning approaches often rely on </span>          <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">correlation rather than causation, researchers are developing causal AI techniques. These methods aim to </span>      <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">identify cause-and-effect relationships within complex systems, enabling more accurate predictions and better</span>  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decision-making.</span>                                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">\u2022 **Growing Importance of Human-AI Collaboration**: As AI capabilities continue to advance, the need for </span>      <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">human-AI collaboration becomes increasingly evident. Researchers are designing systems that facilitate </span>        <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">seamless interaction between humans and AI agents, promoting improved efficiency, productivity, and </span>           <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">innovation.</span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">\u2022 **Increased Focus on AI Ethics and Governance**: The growing influence of AI in various domains has raised </span>  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">concerns about accountability, transparency, and fairness. To address these issues, researchers are </span>           <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">developing new frameworks for AI ethics and governance, emphasizing the need for human oversight and </span>          <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">regulation to ensure responsible AI development and deployment.</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u256d\u2500\u001b[0m\u001b[32m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[32m \u2705 Agent Final Answer \u001b[0m\u001b[32m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[32m\u2500\u256e\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92msenior researcher\u001b[0m                                                                                       \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m\u2022 **Increased Adoption of Explainable AI (XAI)**: With the growing concern about bias and transparency in AI \u001b[0m  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mdecision-making, researchers are focusing on developing methods to explain complex AI models. XAI techniques \u001b[0m  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92maim to provide a clear understanding of how AI systems arrive at their conclusions, enabling users to trust \u001b[0m   \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mand rely on them more effectively.\u001b[0m                                                                             \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m\u2022 **Rise of Edge AI and IoT Convergence**: The proliferation of Internet of Things (IoT) devices has led to \u001b[0m   \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92man explosion in data generation. To address this challenge, researchers are developing edge AI technologies \u001b[0m   \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mthat enable real-time processing and analysis of data at the source, reducing latency and improving \u001b[0m           \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mdecision-making efficiency.\u001b[0m                                                                                    \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m\u2022 **Advancements in Transfer Learning and Few-Shot Learning**: As large datasets become increasingly \u001b[0m          \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mavailable, researchers are exploring ways to transfer knowledge between related tasks or domains. This shift \u001b[0m  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mtowards transfer learning and few-shot learning aims to reduce the need for extensive retraining and improve \u001b[0m  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mmodel adaptability.\u001b[0m                                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m\u2022 **Emergence of Causal AI**: Recognizing that traditional machine learning approaches often rely on \u001b[0m          \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mcorrelation rather than causation, researchers are developing causal AI techniques. These methods aim to \u001b[0m      \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92midentify cause-and-effect relationships within complex systems, enabling more accurate predictions and better\u001b[0m  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mdecision-making.\u001b[0m                                                                                               \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m\u2022 **Growing Importance of Human-AI Collaboration**: As AI capabilities continue to advance, the need for \u001b[0m      \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mhuman-AI collaboration becomes increasingly evident. Researchers are designing systems that facilitate \u001b[0m        \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mseamless interaction between humans and AI agents, promoting improved efficiency, productivity, and \u001b[0m           \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92minnovation.\u001b[0m                                                                                                    \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m\u2022 **Increased Focus on AI Ethics and Governance**: The growing influence of AI in various domains has raised \u001b[0m  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mconcerns about accountability, transparency, and fairness. To address these issues, researchers are \u001b[0m           \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mdeveloping new frameworks for AI ethics and governance, emphasizing the need for human oversight and \u001b[0m          \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mregulation to ensure responsible AI development and deployment.\u001b[0m                                                \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Task Completion \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task Completed</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">f049dc3c-dcaa-4391-881d-3d0f78db0ef9</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">senior researcher</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u256d\u2500\u001b[0m\u001b[32m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[32m Task Completion \u001b[0m\u001b[32m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[32m\u2500\u256e\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[1;32mTask Completed\u001b[0m                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32mf049dc3c-dcaa-4391-881d-3d0f78db0ef9\u001b[0m                                                                     \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[32msenior researcher\u001b[0m                                                                                       \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ud83e\udd16 Agent Started \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Writer</span>                                                                                                  <span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Task: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Write a short blog post about running llama models in Macbook Air M3</span>                                     <span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>                                                                                                                 <span style=\"color: #800080; text-decoration-color: #800080\">\u2502</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[35m\u256d\u2500\u001b[0m\u001b[35m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[35m \ud83e\udd16 Agent Started \u001b[0m\u001b[35m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[35m\u2500\u256e\u001b[0m\n",
       "\u001b[35m\u2502\u001b[0m                                                                                                                 \u001b[35m\u2502\u001b[0m\n",
       "\u001b[35m\u2502\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mWriter\u001b[0m                                                                                                  \u001b[35m\u2502\u001b[0m\n",
       "\u001b[35m\u2502\u001b[0m                                                                                                                 \u001b[35m\u2502\u001b[0m\n",
       "\u001b[35m\u2502\u001b[0m  \u001b[37mTask: \u001b[0m\u001b[92mWrite a short blog post about running llama models in Macbook Air M3\u001b[0m                                     \u001b[35m\u2502\u001b[0m\n",
       "\u001b[35m\u2502\u001b[0m                                                                                                                 \u001b[35m\u2502\u001b[0m\n",
       "\u001b[35m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7e65b5dfd647d79226b35ae72b436b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \u2705 Agent Final Answer \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">Writer</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Answer:</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">**\"Llama Models on MacBook Air M3: A Step-by-Step Guide**</span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Are you ready to unlock the power of Llama models on your trusty MacBook Air M3? In this tutorial, we'll walk</span>  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">you through the process of setting up and running Llama models on Apple's latest laptop powerhouse. With its </span>  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">M3 chip, MacBook Air M3 provides a perfect blend of performance and portability, making it an ideal choice </span>    <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">for AI enthusiasts and professionals alike.</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">**Prerequisites:**</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">* MacBook Air M3 (M3 chip)</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">* macOS Ventura or later</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">* Python 3.8 or later</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">* pip package manager</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">**Step 1: Install Llama Model Requirements**</span>                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">To run Llama models on your MacBook Air M3, you'll need to install the required dependencies using pip:</span>        <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```bash</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pip install transformers llama-pytorch llama-device-quantization</span>                                               <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">**Step 2: Set up Llama Models**</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Next, download and set up a Llama model of your choice. You can use popular models like </span>                       <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">`facebook/llama-base-16384` or `t5-small`. To do this:</span>                                                         <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```python</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from transformers import AutoModelForSeq2SeqLM, AutoTokenizer</span>                                                  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">model_name = \"facebook/llama-base-16384\"</span>                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">tokenizer = AutoTokenizer.from_pretrained(model_name)</span>                                                          <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">model = AutoModelForSeq2SeqLM.from_pretrained(model_name)</span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">**Step 3: Prepare Your Dataset**</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">To fine-tune your Llama model, you'll need a dataset. For this example, let's assume we're working with the </span>   <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">popular `Wikipedia` dataset:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```python</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">import pandas as pd</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">df = pd.read_csv(\"wikipedia.csv\")</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">**Step 4: Fine-Tune Your Llama Model**</span>                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Now it's time to fine-tune your Llama model on your dataset. We'll use a simple sequence-to-sequence </span>          <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">architecture for this example:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```python</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from transformers import Trainer, TrainingArguments</span>                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_args = TrainingArguments(</span>                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    output_dir=\"./results\",</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    num_train_epochs=3,</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    per_device_train_batch_size=16,</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    per_device_eval_batch_size=64,</span>                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    warmup_steps=500,</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    weight_decay=0.01,</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">    logging_dir=\"./logs\"</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">)</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trainer = Trainer(model=model, args=training_args)</span>                                                             <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">trainer.train()</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">**Step 5: Run Your Llama Model**</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Finally, let's run our fine-tuned Llama model on a sample input:</span>                                               <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```python</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">input_text = \"Write a short story about AI taking over the world.\"</span>                                             <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">output_text = tokenizer.encode(input_text, return_tensors=\"pt\")</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">output = model.generate(output_text)</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">print(tokenizer.decode(output[0], skip_special_tokens=True))</span>                                                   <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">Congratulations! You've successfully set up and run Llama models on your MacBook Air M3. With this guide, </span>     <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #00ff00; text-decoration-color: #00ff00\">you're ready to explore the exciting world of AI and unlock its full potential.\"</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u256d\u2500\u001b[0m\u001b[32m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[32m \u2705 Agent Final Answer \u001b[0m\u001b[32m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[32m\u2500\u256e\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[1;92mWriter\u001b[0m                                                                                                  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mFinal Answer:\u001b[0m                                                                                                  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m**\"Llama Models on MacBook Air M3: A Step-by-Step Guide**\u001b[0m                                                      \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mAre you ready to unlock the power of Llama models on your trusty MacBook Air M3? In this tutorial, we'll walk\u001b[0m  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92myou through the process of setting up and running Llama models on Apple's latest laptop powerhouse. With its \u001b[0m  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mM3 chip, MacBook Air M3 provides a perfect blend of performance and portability, making it an ideal choice \u001b[0m    \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mfor AI enthusiasts and professionals alike.\u001b[0m                                                                    \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m**Prerequisites:**\u001b[0m                                                                                             \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m* MacBook Air M3 (M3 chip)\u001b[0m                                                                                     \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m* macOS Ventura or later\u001b[0m                                                                                       \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m* Python 3.8 or later\u001b[0m                                                                                          \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m* pip package manager\u001b[0m                                                                                          \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m**Step 1: Install Llama Model Requirements**\u001b[0m                                                                   \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mTo run Llama models on your MacBook Air M3, you'll need to install the required dependencies using pip:\u001b[0m        \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m```bash\u001b[0m                                                                                                        \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mpip install transformers llama-pytorch llama-device-quantization\u001b[0m                                               \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m```\u001b[0m                                                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m**Step 2: Set up Llama Models**\u001b[0m                                                                                \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mNext, download and set up a Llama model of your choice. You can use popular models like \u001b[0m                       \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m`facebook/llama-base-16384` or `t5-small`. To do this:\u001b[0m                                                         \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m```python\u001b[0m                                                                                                      \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\u001b[0m                                                  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mmodel_name = \"facebook/llama-base-16384\"\u001b[0m                                                                       \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mtokenizer = AutoTokenizer.from_pretrained(model_name)\u001b[0m                                                          \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\u001b[0m                                                      \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m```\u001b[0m                                                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m**Step 3: Prepare Your Dataset**\u001b[0m                                                                               \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mTo fine-tune your Llama model, you'll need a dataset. For this example, let's assume we're working with the \u001b[0m   \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mpopular `Wikipedia` dataset:\u001b[0m                                                                                   \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m```python\u001b[0m                                                                                                      \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mimport pandas as pd\u001b[0m                                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mdf = pd.read_csv(\"wikipedia.csv\")\u001b[0m                                                                              \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m```\u001b[0m                                                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m**Step 4: Fine-Tune Your Llama Model**\u001b[0m                                                                         \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mNow it's time to fine-tune your Llama model on your dataset. We'll use a simple sequence-to-sequence \u001b[0m          \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92marchitecture for this example:\u001b[0m                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m```python\u001b[0m                                                                                                      \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mfrom transformers import Trainer, TrainingArguments\u001b[0m                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mtraining_args = TrainingArguments(\u001b[0m                                                                             \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m    output_dir=\"./results\",\u001b[0m                                                                                    \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m    num_train_epochs=3,\u001b[0m                                                                                        \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m    per_device_train_batch_size=16,\u001b[0m                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m    per_device_eval_batch_size=64,\u001b[0m                                                                             \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m    warmup_steps=500,\u001b[0m                                                                                          \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m    weight_decay=0.01,\u001b[0m                                                                                         \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m    logging_dir=\"./logs\"\u001b[0m                                                                                       \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m)\u001b[0m                                                                                                              \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mtrainer = Trainer(model=model, args=training_args)\u001b[0m                                                             \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mtrainer.train()\u001b[0m                                                                                                \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m```\u001b[0m                                                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m**Step 5: Run Your Llama Model**\u001b[0m                                                                               \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mFinally, let's run our fine-tuned Llama model on a sample input:\u001b[0m                                               \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m```python\u001b[0m                                                                                                      \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92minput_text = \"Write a short story about AI taking over the world.\"\u001b[0m                                             \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92moutput_text = tokenizer.encode(input_text, return_tensors=\"pt\")\u001b[0m                                                \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92moutput = model.generate(output_text)\u001b[0m                                                                           \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mprint(tokenizer.decode(output[0], skip_special_tokens=True))\u001b[0m                                                   \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92m```\u001b[0m                                                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92mCongratulations! You've successfully set up and run Llama models on your MacBook Air M3. With this guide, \u001b[0m     \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[92myou're ready to explore the exciting world of AI and unlock its full potential.\"\u001b[0m                               \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Crew Completion \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Crew Execution Completed</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">crew</span>                                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">ID: </span><span style=\"color: #008000; text-decoration-color: #008000\">6597fdea-4dbf-4057-8da0-0faf4c17a77d</span>                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Final Output: **\"Llama Models on MacBook Air M3: A Step-by-Step Guide**</span>                                        <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Are you ready to unlock the power of Llama models on your trusty MacBook Air M3? In this tutorial, we'll walk</span>  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">you through the process of setting up and running Llama models on Apple's latest laptop powerhouse. With its </span>  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">M3 chip, MacBook Air M3 provides a perfect blend of performance and portability, making it an ideal choice </span>    <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">for AI enthusiasts and professionals alike.</span>                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">**Prerequisites:**</span>                                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">* MacBook Air M3 (M3 chip)</span>                                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">* macOS Ventura or later</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">* Python 3.8 or later</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">* pip package manager</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">**Step 1: Install Llama Model Requirements**</span>                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">To run Llama models on your MacBook Air M3, you'll need to install the required dependencies using pip:</span>        <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```bash</span>                                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">pip install transformers llama-pytorch llama-device-quantization</span>                                               <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">**Step 2: Set up Llama Models**</span>                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Next, download and set up a Llama model of your choice. You can use popular models like </span>                       <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">`facebook/llama-base-16384` or `t5-small`. To do this:</span>                                                         <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```python</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">from transformers import AutoModelForSeq2SeqLM, AutoTokenizer</span>                                                  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">model_name = \"facebook/llama-base-16384\"</span>                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">tokenizer = AutoTokenizer.from_pretrained(model_name)</span>                                                          <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">model = AutoModelForSeq2SeqLM.from_pretrained(model_name)</span>                                                      <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">**Step 3: Prepare Your Dataset**</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">To fine-tune your Llama model, you'll need a dataset. For this example, let's assume we're working with the </span>   <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">popular `Wikipedia` dataset:</span>                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```python</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">import pandas as pd</span>                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">df = pd.read_csv(\"wikipedia.csv\")</span>                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">**Step 4: Fine-Tune Your Llama Model**</span>                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Now it's time to fine-tune your Llama model on your dataset. We'll use a simple sequence-to-sequence </span>          <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">architecture for this example:</span>                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```python</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">from transformers import Trainer, TrainingArguments</span>                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">training_args = TrainingArguments(</span>                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    output_dir=\"./results\",</span>                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    num_train_epochs=3,</span>                                                                                        <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    per_device_train_batch_size=16,</span>                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    per_device_eval_batch_size=64,</span>                                                                             <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    warmup_steps=500,</span>                                                                                          <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    weight_decay=0.01,</span>                                                                                         <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">    logging_dir=\"./logs\"</span>                                                                                       <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">)</span>                                                                                                              <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">trainer = Trainer(model=model, args=training_args)</span>                                                             <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">trainer.train()</span>                                                                                                <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">**Step 5: Run Your Llama Model**</span>                                                                               <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Finally, let's run our fine-tuned Llama model on a sample input:</span>                                               <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```python</span>                                                                                                      <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">input_text = \"Write a short story about AI taking over the world.\"</span>                                             <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output_text = tokenizer.encode(input_text, return_tensors=\"pt\")</span>                                                <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">output = model.generate(output_text)</span>                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">print(tokenizer.decode(output[0], skip_special_tokens=True))</span>                                                   <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">```</span>                                                                                                            <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Congratulations! You've successfully set up and run Llama models on your MacBook Air M3. With this guide, </span>     <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">you're ready to explore the exciting world of AI and unlock its full potential.\"</span>                               <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u256d\u2500\u001b[0m\u001b[32m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[32m Crew Completion \u001b[0m\u001b[32m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[32m\u2500\u256e\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[1;32mCrew Execution Completed\u001b[0m                                                                                       \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32mcrew\u001b[0m                                                                                                     \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mID: \u001b[0m\u001b[32m6597fdea-4dbf-4057-8da0-0faf4c17a77d\u001b[0m                                                                       \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mFinal Output: **\"Llama Models on MacBook Air M3: A Step-by-Step Guide**\u001b[0m                                        \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mAre you ready to unlock the power of Llama models on your trusty MacBook Air M3? In this tutorial, we'll walk\u001b[0m  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37myou through the process of setting up and running Llama models on Apple's latest laptop powerhouse. With its \u001b[0m  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mM3 chip, MacBook Air M3 provides a perfect blend of performance and portability, making it an ideal choice \u001b[0m    \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mfor AI enthusiasts and professionals alike.\u001b[0m                                                                    \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m**Prerequisites:**\u001b[0m                                                                                             \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m* MacBook Air M3 (M3 chip)\u001b[0m                                                                                     \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m* macOS Ventura or later\u001b[0m                                                                                       \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m* Python 3.8 or later\u001b[0m                                                                                          \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m* pip package manager\u001b[0m                                                                                          \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m**Step 1: Install Llama Model Requirements**\u001b[0m                                                                   \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mTo run Llama models on your MacBook Air M3, you'll need to install the required dependencies using pip:\u001b[0m        \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m```bash\u001b[0m                                                                                                        \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mpip install transformers llama-pytorch llama-device-quantization\u001b[0m                                               \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m```\u001b[0m                                                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m**Step 2: Set up Llama Models**\u001b[0m                                                                                \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mNext, download and set up a Llama model of your choice. You can use popular models like \u001b[0m                       \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m`facebook/llama-base-16384` or `t5-small`. To do this:\u001b[0m                                                         \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m```python\u001b[0m                                                                                                      \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer\u001b[0m                                                  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mmodel_name = \"facebook/llama-base-16384\"\u001b[0m                                                                       \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mtokenizer = AutoTokenizer.from_pretrained(model_name)\u001b[0m                                                          \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\u001b[0m                                                      \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m```\u001b[0m                                                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m**Step 3: Prepare Your Dataset**\u001b[0m                                                                               \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mTo fine-tune your Llama model, you'll need a dataset. For this example, let's assume we're working with the \u001b[0m   \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mpopular `Wikipedia` dataset:\u001b[0m                                                                                   \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m```python\u001b[0m                                                                                                      \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mimport pandas as pd\u001b[0m                                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mdf = pd.read_csv(\"wikipedia.csv\")\u001b[0m                                                                              \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m```\u001b[0m                                                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m**Step 4: Fine-Tune Your Llama Model**\u001b[0m                                                                         \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mNow it's time to fine-tune your Llama model on your dataset. We'll use a simple sequence-to-sequence \u001b[0m          \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37marchitecture for this example:\u001b[0m                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m```python\u001b[0m                                                                                                      \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mfrom transformers import Trainer, TrainingArguments\u001b[0m                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mtraining_args = TrainingArguments(\u001b[0m                                                                             \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m    output_dir=\"./results\",\u001b[0m                                                                                    \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m    num_train_epochs=3,\u001b[0m                                                                                        \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m    per_device_train_batch_size=16,\u001b[0m                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m    per_device_eval_batch_size=64,\u001b[0m                                                                             \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m    warmup_steps=500,\u001b[0m                                                                                          \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m    weight_decay=0.01,\u001b[0m                                                                                         \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m    logging_dir=\"./logs\"\u001b[0m                                                                                       \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m)\u001b[0m                                                                                                              \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mtrainer = Trainer(model=model, args=training_args)\u001b[0m                                                             \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mtrainer.train()\u001b[0m                                                                                                \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m```\u001b[0m                                                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m**Step 5: Run Your Llama Model**\u001b[0m                                                                               \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mFinally, let's run our fine-tuned Llama model on a sample input:\u001b[0m                                               \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m```python\u001b[0m                                                                                                      \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37minput_text = \"Write a short story about AI taking over the world.\"\u001b[0m                                             \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37moutput_text = tokenizer.encode(input_text, return_tensors=\"pt\")\u001b[0m                                                \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37moutput = model.generate(output_text)\u001b[0m                                                                           \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mprint(tokenizer.decode(output[0], skip_special_tokens=True))\u001b[0m                                                   \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37m```\u001b[0m                                                                                                            \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mCongratulations! You've successfully set up and run Llama models on your MacBook Air M3. With this guide, \u001b[0m     \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37myou're ready to explore the exciting world of AI and unlock its full potential.\"\u001b[0m                               \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Task Completion \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Task Completed</span>                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Name: </span><span style=\"color: #008000; text-decoration-color: #008000\">14b16a8b-fb7f-4e4b-a111-900d93be7b34</span>                                                                     <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Agent: </span><span style=\"color: #008000; text-decoration-color: #008000\">Writer</span>                                                                                                  <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">Tool Args: </span>                                                                                                    <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>                                                                                                                 <span style=\"color: #008000; text-decoration-color: #008000\">\u2502</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\u256d\u2500\u001b[0m\u001b[32m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[32m Task Completion \u001b[0m\u001b[32m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[32m\u2500\u256e\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[1;32mTask Completed\u001b[0m                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mName: \u001b[0m\u001b[32m14b16a8b-fb7f-4e4b-a111-900d93be7b34\u001b[0m                                                                     \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mAgent: \u001b[0m\u001b[32mWriter\u001b[0m                                                                                                  \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m  \u001b[37mTool Args: \u001b[0m                                                                                                    \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2502\u001b[0m                                                                                                                 \u001b[32m\u2502\u001b[0m\n",
       "\u001b[32m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">\u256d\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Tracing Status \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256e</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>  Info: Tracing is disabled.                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>  To enable tracing, do any one of these:                                                                        <span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>  \u2022 Set tracing=True in your Crew/Flow code                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>  \u2022 Set CREWAI_TRACING_ENABLED=true in your project's .env file                                                  <span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>  \u2022 Run: crewai traces enable                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">\u2502</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m\u256d\u2500\u001b[0m\u001b[34m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[34m Tracing Status \u001b[0m\u001b[34m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[34m\u2500\u256e\u001b[0m\n",
       "\u001b[34m\u2502\u001b[0m                                                                                                                 \u001b[34m\u2502\u001b[0m\n",
       "\u001b[34m\u2502\u001b[0m  Info: Tracing is disabled.                                                                                     \u001b[34m\u2502\u001b[0m\n",
       "\u001b[34m\u2502\u001b[0m                                                                                                                 \u001b[34m\u2502\u001b[0m\n",
       "\u001b[34m\u2502\u001b[0m  To enable tracing, do any one of these:                                                                        \u001b[34m\u2502\u001b[0m\n",
       "\u001b[34m\u2502\u001b[0m  \u2022 Set tracing=True in your Crew/Flow code                                                                      \u001b[34m\u2502\u001b[0m\n",
       "\u001b[34m\u2502\u001b[0m  \u2022 Set CREWAI_TRACING_ENABLED=true in your project's .env file                                                  \u001b[34m\u2502\u001b[0m\n",
       "\u001b[34m\u2502\u001b[0m  \u2022 Run: crewai traces enable                                                                                    \u001b[34m\u2502\u001b[0m\n",
       "\u001b[34m\u2502\u001b[0m                                                                                                                 \u001b[34m\u2502\u001b[0m\n",
       "\u001b[34m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Kickoff\n",
    "result = crew.kickoff()\n",
    "print(\"Result: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09185d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}